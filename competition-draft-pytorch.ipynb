{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from einops import rearrange\n",
    "from PIL import Image\n",
    "from pytorch_lightning.callbacks import (Callback, EarlyStopping,\n",
    "                                         LearningRateMonitor, ModelCheckpoint,\n",
    "                                         ProgressBar)\n",
    "from torchmetrics import Precision, Recall, Specificity\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader, Dataset, Sampler, Subset\n",
    "from torchmetrics import Metric\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "pl.seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2024 ISIC Challenge primary prize scoring metric\n",
    "\n",
    "Given a list of binary labels, an associated list of prediction \n",
    "scores ranging from [0,1], this function produces, as a single value, \n",
    "the partial area under the receiver operating characteristic (pAUC) \n",
    "above a given true positive rate (TPR).\n",
    "https://en.wikipedia.org/wiki/Partial_Area_Under_the_ROC_Curve.\n",
    "\n",
    "(c) 2024 Nicholas R Kurtansky, MSKCC\n",
    "\"\"\"\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "class PartialAUROC(Metric):\n",
    "    def __init__(\n",
    "        self,\n",
    "        min_tpr: float = 0.80,\n",
    "        dist_sync_on_step: bool = False,\n",
    "    ):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "        self.min_tpr = min_tpr\n",
    "        self.add_state(\"preds\", default=[], dist_reduce_fx=\"cat\")\n",
    "        self.add_state(\"target\", default=[], dist_reduce_fx=\"cat\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        self.preds.append(preds)\n",
    "        self.target.append(target)\n",
    "\n",
    "    def compute(self):\n",
    "        preds = torch.cat(self.preds)\n",
    "        target = torch.cat(self.target)\n",
    "        return self._partial_auroc(target, preds, self.min_tpr)\n",
    "\n",
    "    def _partial_auroc(\n",
    "        self, y_true: torch.Tensor, y_score: torch.Tensor, min_tpr: float\n",
    "    ) -> float:\n",
    "        y_true = torch.abs(y_true - 1)\n",
    "        y_score = -y_score\n",
    "\n",
    "        fpr, tpr, _ = self._roc_curve(y_true, y_score)\n",
    "        max_fpr = 1.0 - min_tpr\n",
    "\n",
    "        # print(f\"Computed FPR: {fpr}\")\n",
    "        # print(f\"Computed TPR: {tpr}\")\n",
    "\n",
    "        if max_fpr == 1:\n",
    "            return self._auc(fpr, tpr)\n",
    "        if max_fpr <= 0 or max_fpr > 1:\n",
    "            raise ValueError(f\"Expected min_tpr in range [0, 1), got: {min_tpr}\")\n",
    "\n",
    "        stop = torch.searchsorted(fpr, torch.tensor(max_fpr), right=True)\n",
    "        x_interp = fpr[stop - 1 : stop + 1]\n",
    "        y_interp = tpr[stop - 1 : stop + 1]\n",
    "\n",
    "        # print(f\"x_interp: {x_interp}\")\n",
    "        # print(f\"y_interp: {y_interp}\")\n",
    "\n",
    "        if len(x_interp) == 1:\n",
    "            interp_tpr = y_interp[0]\n",
    "        else:\n",
    "            interp_tpr = y_interp[0] + (max_fpr - x_interp[0]) * (\n",
    "                y_interp[1] - y_interp[0]\n",
    "            ) / (x_interp[1] - x_interp[0])\n",
    "\n",
    "        tpr = torch.cat([tpr[:stop], torch.tensor([interp_tpr])])\n",
    "        fpr = torch.cat([fpr[:stop], torch.tensor([max_fpr])])\n",
    "\n",
    "        partial_auc = self._auc(fpr, tpr)\n",
    "        return partial_auc\n",
    "\n",
    "    def _roc_curve(self, y_true: torch.Tensor, y_score: torch.Tensor):\n",
    "        desc_score_indices = torch.argsort(y_score, descending=True)\n",
    "        y_score = y_score[desc_score_indices]\n",
    "        y_true = y_true[desc_score_indices]\n",
    "\n",
    "        distinct_value_indices = torch.where(torch.diff(y_score))[0]\n",
    "        threshold_idxs = torch.cat(\n",
    "            [distinct_value_indices, torch.tensor([y_true.numel() - 1])]\n",
    "        )\n",
    "\n",
    "        tps = torch.cumsum(y_true, dim=0)[threshold_idxs]\n",
    "        fps = 1 + threshold_idxs - tps\n",
    "        \n",
    "        # Handle the case where there are no positive samples\n",
    "        if tps[-1] == 0:\n",
    "            tpr = torch.zeros_like(tps)\n",
    "        else:\n",
    "            tpr = tps / tps[-1]\n",
    "        \n",
    "        fpr = fps / fps[-1]\n",
    "        thresholds = y_score[threshold_idxs]\n",
    "\n",
    "        # print(f\"tps: {tps}\")\n",
    "        # print(f\"fps: {fps}\")\n",
    "        # print(f\"tpr: {tpr}\")\n",
    "        # print(f\"fpr: {fpr}\")\n",
    "        # print(f\"thresholds: {thresholds}\")\n",
    "\n",
    "        return fpr, tpr, thresholds\n",
    "\n",
    "    def _auc(self, x: torch.Tensor, y: torch.Tensor) -> float:\n",
    "        if torch.all(y == 0):\n",
    "            print(\"Warning: All TPR values are zero. AUC is undefined.\")\n",
    "            return 0.0\n",
    "\n",
    "        direction = 1\n",
    "        dx = torch.diff(x)\n",
    "        if torch.any(dx < 0):\n",
    "            if torch.all(dx <= 0):\n",
    "                direction = -1\n",
    "            else:\n",
    "                raise ValueError(\"x is neither increasing nor decreasing\")\n",
    "        auc_value = direction * torch.trapz(y, x).item()\n",
    "        # print(f\"Computed AUC: {auc_value}\")\n",
    "        return auc_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cu121\n",
      "0.19.0+cu121\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "print(pl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, filters):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(\n",
    "            filters, filters, kernel_size=3, padding=1, groups=filters\n",
    "        )\n",
    "        self.pointwise = nn.Conv2d(filters, filters, kernel_size=1)\n",
    "        self.conv1x1 = nn.Conv2d(filters, filters, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm2d(filters)\n",
    "        self.bn2 = nn.BatchNorm2d(filters)\n",
    "        self.att_conv = nn.Conv2d(filters, 1, kernel_size=1)\n",
    "        self.bn_att = nn.BatchNorm2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        g = self.depthwise(x)\n",
    "        g = self.pointwise(g)\n",
    "        x = self.conv1x1(x)\n",
    "        g = self.bn1(g)\n",
    "        x = self.bn2(x)\n",
    "        g = F.relu(g)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        att = g + x\n",
    "        att = self.att_conv(att)\n",
    "        att = self.bn_att(att)\n",
    "        att = torch.sigmoid(att)\n",
    "\n",
    "        return x * att\n",
    "\n",
    "\n",
    "class MultiScaleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1x1 = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=1, padding=\"same\"\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.depthwise3x3 = nn.Conv2d(\n",
    "            in_channels, in_channels, kernel_size=3, padding=\"same\", groups=in_channels\n",
    "        )\n",
    "        self.pointwise3x3 = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=1, padding=\"same\"\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.depthwise5x5 = nn.Conv2d(\n",
    "            in_channels, in_channels, kernel_size=5, padding=\"same\", groups=in_channels\n",
    "        )\n",
    "        self.pointwise5x5 = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=1, padding=\"same\"\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.output_conv = nn.Conv2d(\n",
    "            out_channels * 3, out_channels, kernel_size=1, padding=\"same\"\n",
    "        )\n",
    "        self.bn_out = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1x1 = F.hardswish(self.bn1(self.conv1x1(x)))\n",
    "\n",
    "        conv3x3 = self.depthwise3x3(x)\n",
    "        conv3x3 = F.hardswish(self.bn2(self.pointwise3x3(conv3x3)))\n",
    "\n",
    "        conv5x5 = self.depthwise5x5(x)\n",
    "        conv5x5 = F.hardswish(self.bn3(self.pointwise5x5(conv5x5)))\n",
    "\n",
    "        concat = torch.cat([conv1x1, conv3x3, conv5x5], dim=1)\n",
    "\n",
    "        output = F.hardswish(self.bn_out(self.output_conv(concat)))\n",
    "        return output\n",
    "\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, ratio=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(in_channels, in_channels // ratio)\n",
    "        self.fc2 = nn.Linear(in_channels // ratio, in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = F.relu(self.fc1(y))\n",
    "        y = torch.sigmoid(self.fc2(y)).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "\n",
    "class GatedResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, filters, kernel_size, strides):\n",
    "        super().__init__()\n",
    "        # Calculate padding\n",
    "        padding = (kernel_size - 1) // 2\n",
    "\n",
    "        self.depthwise_shortcut = nn.Conv2d(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=1,\n",
    "            stride=strides,\n",
    "            padding=0,  # No padding for 1x1 conv\n",
    "            groups=in_channels,\n",
    "        )\n",
    "        self.pointwise_shortcut = nn.Conv2d(\n",
    "            in_channels, filters, kernel_size=1, padding=0\n",
    "        )\n",
    "        self.bn_shortcut = nn.BatchNorm2d(filters)\n",
    "\n",
    "        self.depthwise = nn.Conv2d(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=strides,\n",
    "            padding=padding,\n",
    "            groups=in_channels,\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.pointwise = nn.Conv2d(in_channels, filters, kernel_size=1)\n",
    "        self.bn2 = nn.BatchNorm2d(filters)\n",
    "\n",
    "        self.gate = nn.Conv2d(filters, filters, kernel_size=1)\n",
    "        self.bn_gate = nn.BatchNorm2d(filters)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.bn_shortcut(self.pointwise_shortcut(self.depthwise_shortcut(x)))\n",
    "\n",
    "        x = F.hardswish(self.bn1(self.depthwise(x)))\n",
    "        x = self.bn2(self.pointwise(x))\n",
    "\n",
    "        gate = torch.sigmoid(self.bn_gate(self.gate(x)))\n",
    "\n",
    "        x = x * gate\n",
    "        x = x + shortcut\n",
    "        return F.hardswish(x)\n",
    "\n",
    "\n",
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, f1, f2, f3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, f1, kernel_size=1, padding=\"same\")\n",
    "        self.bn1 = nn.BatchNorm2d(f1)\n",
    "\n",
    "        self.conv3_reduce = nn.Conv2d(in_channels, f2[0], kernel_size=1, padding=\"same\")\n",
    "        self.bn3_reduce = nn.BatchNorm2d(f2[0])\n",
    "        self.conv3_depthwise = nn.Conv2d(\n",
    "            f2[0], f2[0], kernel_size=3, padding=\"same\", groups=f2[0]\n",
    "        )\n",
    "        self.conv3_pointwise = nn.Conv2d(f2[0], f2[1], kernel_size=1, padding=\"same\")\n",
    "        self.bn3 = nn.BatchNorm2d(f2[1])\n",
    "\n",
    "        self.conv5_reduce = nn.Conv2d(in_channels, f3[0], kernel_size=1, padding=\"same\")\n",
    "        self.bn5_reduce = nn.BatchNorm2d(f3[0])\n",
    "        self.conv5_depthwise = nn.Conv2d(\n",
    "            f3[0], f3[0], kernel_size=5, padding=\"same\", groups=f3[0]\n",
    "        )\n",
    "        self.conv5_pointwise = nn.Conv2d(f3[0], f3[1], kernel_size=1, padding=\"same\")\n",
    "        self.bn5 = nn.BatchNorm2d(f3[1])\n",
    "\n",
    "        self.pool_proj = nn.Conv2d(in_channels, f1, kernel_size=1, padding=\"same\")\n",
    "        self.bn_pool = nn.BatchNorm2d(f1)\n",
    "\n",
    "        self.output_conv = nn.Conv2d(\n",
    "            f1 + f2[1] + f3[1] + f1,\n",
    "            sum([f1, f2[1], f3[1], f1]),\n",
    "            kernel_size=1,\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        self.bn_out = nn.BatchNorm2d(sum([f1, f2[1], f3[1], f1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = F.hardswish(self.bn1(self.conv1(x)))\n",
    "\n",
    "        conv3 = F.hardswish(self.bn3_reduce(self.conv3_reduce(x)))\n",
    "        conv3 = self.conv3_depthwise(conv3)\n",
    "        conv3 = F.hardswish(self.bn3(self.conv3_pointwise(conv3)))\n",
    "\n",
    "        conv5 = F.hardswish(self.bn5_reduce(self.conv5_reduce(x)))\n",
    "        conv5 = self.conv5_depthwise(conv5)\n",
    "        conv5 = F.hardswish(self.bn5(self.conv5_pointwise(conv5)))\n",
    "\n",
    "        pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        pool = F.hardswish(self.bn_pool(self.pool_proj(pool)))\n",
    "\n",
    "        output = torch.cat([conv1, conv3, conv5, pool], dim=1)\n",
    "        output = F.hardswish(self.bn_out(self.output_conv(output)))\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, num_layers, growth_rate, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(\n",
    "                self._make_dense_layer(\n",
    "                    in_channels + i * growth_rate, growth_rate, dropout_rate\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def _make_dense_layer(self, in_channels, growth_rate, dropout_rate):\n",
    "        return nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels, 4 * growth_rate, kernel_size=1, bias=False),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.BatchNorm2d(4 * growth_rate),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                4 * growth_rate, growth_rate, kernel_size=3, padding=1, bias=False\n",
    "            ),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = [x]\n",
    "        for layer in self.layers:\n",
    "            new_features = layer(torch.cat(features, 1))\n",
    "            features.append(new_features)\n",
    "        return torch.cat(features, 1)\n",
    "\n",
    "\n",
    "class TransitionLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        x = F.hardswish(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TopLayer(nn.Module):\n",
    "    def __init__(self, in_features, num_classes, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class InvertedResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expand_ratio, stride):\n",
    "        super().__init__()\n",
    "        hidden_dim = in_channels * expand_ratio\n",
    "        self.use_res_connect = stride == 1 and in_channels == out_channels\n",
    "\n",
    "        layers = []\n",
    "        if expand_ratio != 1:\n",
    "            layers.append(nn.Conv2d(in_channels, hidden_dim, 1, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(hidden_dim))\n",
    "            layers.append(nn.SiLU(inplace=True))\n",
    "\n",
    "        layers.extend(\n",
    "            [\n",
    "                nn.Conv2d(\n",
    "                    hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.SiLU(inplace=True),\n",
    "                nn.Conv2d(hidden_dim, out_channels, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        self.se = SEBlock(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.se(self.conv(x))\n",
    "        else:\n",
    "            return self.se(self.conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expand_ratio, stride):\n",
    "        super(InvertedResidualBlock, self).__init__()\n",
    "        hidden_dim = in_channels * expand_ratio\n",
    "        self.use_res_connect = stride == 1 and in_channels == out_channels\n",
    "\n",
    "        layers = []\n",
    "        if expand_ratio != 1:\n",
    "            layers.append(ConvBNActivation(in_channels, hidden_dim, kernel_size=1))\n",
    "        layers.extend(\n",
    "            [\n",
    "                ConvBNActivation(\n",
    "                    hidden_dim, hidden_dim, stride=stride, groups=hidden_dim\n",
    "                ),\n",
    "                nn.Conv2d(hidden_dim, out_channels, 1, bias=True),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            ]\n",
    "        )\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class ConvBNActivation(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, groups=1):\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        super(ConvBNActivation, self).__init__(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                groups=groups,\n",
    "                bias=True,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Mish(),\n",
    "        )\n",
    "\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, num_layers, growth_rate, dropout_rate=0.2):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                DenseLayer(in_channels + i * growth_rate, growth_rate, dropout_rate)\n",
    "                for i in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = torch.cat([x, layer(x)], 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DenseLayer(nn.Sequential):\n",
    "    def __init__(self, in_channels, growth_rate, dropout_rate):\n",
    "        super(DenseLayer, self).__init__(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.Mish(),\n",
    "            nn.Conv2d(in_channels, 4 * growth_rate, 1, bias=True),\n",
    "            nn.BatchNorm2d(4 * growth_rate),\n",
    "            nn.Mish(),\n",
    "            nn.Conv2d(4 * growth_rate, growth_rate, 3, padding=1, bias=True),\n",
    "            nn.Dropout2d(dropout_rate),\n",
    "        )\n",
    "\n",
    "\n",
    "class TransitionLayer(nn.Sequential):\n",
    "    def __init__(self, in_channels, compression_factor=0.5):\n",
    "        out_channels = int(in_channels * compression_factor)\n",
    "        super(TransitionLayer, self).__init__(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.Mish(),\n",
    "            nn.Conv2d(in_channels, out_channels, 1, bias=True),\n",
    "            nn.AvgPool2d(2, stride=2),\n",
    "        )\n",
    "\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, 1, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        g = self.bn1(self.conv1(x))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        att = nn.Hardswish()(g + x)\n",
    "        att = nn.Sigmoid()(self.bn3(self.conv3(att)))\n",
    "        return x * att\n",
    "\n",
    "\n",
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, filters):\n",
    "        super(InceptionBlock, self).__init__()\n",
    "        f1, f2, f3 = filters\n",
    "        self.branch1 = ConvBNActivation(in_channels, f1, kernel_size=1)\n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBNActivation(in_channels, f2[0], kernel_size=1),\n",
    "            ConvBNActivation(f2[0], f2[1], kernel_size=3),\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            ConvBNActivation(in_channels, f3[0], kernel_size=1),\n",
    "            ConvBNActivation(f3[0], f3[1], kernel_size=5),\n",
    "        )\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            ConvBNActivation(in_channels, f1, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "        return torch.cat([branch1, branch2, branch3, branch4], 1)\n",
    "\n",
    "\n",
    "class GatedResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, strides):\n",
    "        super(GatedResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=strides,\n",
    "            padding=kernel_size // 2,\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = nn.Mish()\n",
    "\n",
    "        # Add a shortcut connection if input and output dimensions don't match\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if strides != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels, out_channels, kernel_size=1, stride=strides, bias=True\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "\n",
    "        x = self.activation(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        gate = nn.Sigmoid()(self.bn3(self.conv3(x)))\n",
    "        x = x * gate\n",
    "        x += residual\n",
    "        return self.activation(x)\n",
    "\n",
    "\n",
    "class GuruNet(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape=(139, 139, 3),\n",
    "        metadata_shape=None,\n",
    "        classes=2,\n",
    "    ):\n",
    "        super(GuruNet, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.metadata_shape = metadata_shape\n",
    "\n",
    "        # Initial convolutional layer\n",
    "        self.conv1 = nn.Conv2d(3, 256, kernel_size=5, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(256)\n",
    "        self.activation = nn.Hardswish()\n",
    "\n",
    "        # Inverted Residual Blocks\n",
    "        self.inv_res_blocks = nn.ModuleList()\n",
    "        block_params = [\n",
    "            # expand_ratio, filters, strides, repeats\n",
    "            (6, 16, 1, 1),\n",
    "            (6, 24, 2, 2),\n",
    "            (6, 40, 2, 2),\n",
    "            (6, 80, 2, 3),\n",
    "            (6, 112, 1, 3),\n",
    "            (6, 128, 2, 4),\n",
    "            (6, 196, 1, 1),\n",
    "        ]\n",
    "\n",
    "        in_channels = 256\n",
    "        for i, (expand_ratio, filters, strides, repeats) in enumerate(block_params):\n",
    "            for j in range(repeats):\n",
    "                if j > 0:\n",
    "                    strides = 1\n",
    "                self.inv_res_blocks.append(\n",
    "                    InvertedResidualBlock(in_channels, filters, expand_ratio, strides)\n",
    "                )\n",
    "                in_channels = filters\n",
    "\n",
    "        # Dense Block\n",
    "        self.dense_block = DenseBlock(in_channels, num_layers=20, growth_rate=32)\n",
    "        in_channels += 20 * 32  # Update in_channels after dense block\n",
    "\n",
    "        # Transition Layer\n",
    "        self.transition = TransitionLayer(in_channels, compression_factor=0.5)\n",
    "        in_channels = int(in_channels * 0.5)\n",
    "\n",
    "        # Attention Block\n",
    "        self.attention = AttentionBlock(in_channels, 256)\n",
    "        in_channels = 256\n",
    "\n",
    "        # Average Pooling\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Inception Block\n",
    "        self.inception = InceptionBlock(in_channels, [128, (128, 192), (32, 96)])\n",
    "        in_channels = 128 + 192 + 96 + 128\n",
    "\n",
    "        self.inception2 = InceptionBlock(in_channels, [128, (128, 192), (32, 96)])\n",
    "        in_channels = 128 + 192 + 96 + 128\n",
    "\n",
    "        # Attention Block\n",
    "        self.attention2 = AttentionBlock(in_channels, 256)\n",
    "        in_channels = 256\n",
    "\n",
    "        # Gated Residual Block\n",
    "        self.gated_res = GatedResidualBlock(in_channels, 512, kernel_size=3, strides=2)\n",
    "        in_channels = 512\n",
    "\n",
    "        # Attention Block\n",
    "        self.attention3 = AttentionBlock(in_channels, 256)\n",
    "        in_channels = 256\n",
    "\n",
    "        # Global Average Pooling\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(in_channels, 4096)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(4096)\n",
    "        self.fc2 = nn.Linear(4096, 2048)\n",
    "        self.bn_fc2 = nn.BatchNorm1d(2048)\n",
    "        self.fc3 = nn.Linear(2048, 512)\n",
    "        self.bn_fc3 = nn.BatchNorm1d(512)\n",
    "        self.fc4 = nn.Linear(512, 128)\n",
    "        self.bn_fc4 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.metadata_fc1 = nn.Linear(41, 4096)\n",
    "        self.metadata_bn1 = nn.BatchNorm1d(4096)\n",
    "        self.metadata_fc2 = nn.Linear(4096, 1024)\n",
    "        self.metadata_bn2 = nn.BatchNorm1d(1024)\n",
    "        self.metadata_fc3 = nn.Linear(1024, 512)\n",
    "        self.metadata_bn3 = nn.BatchNorm1d(512)\n",
    "        self.metadata_fc4 = nn.Linear(512, 128)\n",
    "        self.metadata_bn4 = nn.BatchNorm1d(128)\n",
    "        self.final_fc = nn.Linear(128 + 128, classes)\n",
    "        self.final_activation = nn.Sigmoid()\n",
    "        self.scaler = GradScaler()\n",
    "        self.loss = self.loss = nn.CrossEntropyLoss()\n",
    "        self.auroc = PartialAUROC(min_tpr=0.8)\n",
    "\n",
    "    def forward(self, x, metadata):\n",
    "        x = self.activation(self.bn1(self.conv1(x)))\n",
    "\n",
    "        # Inverted Residual Blocks\n",
    "        for block in self.inv_res_blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        # Dense Block\n",
    "        x = self.dense_block(x)\n",
    "\n",
    "        # Transition Layer\n",
    "        x = self.transition(x)\n",
    "\n",
    "        # Attention Block\n",
    "        x = self.attention(x)\n",
    "\n",
    "        # Average Pooling\n",
    "        x = self.avg_pool(x)\n",
    "\n",
    "        # Inception Block\n",
    "        x = self.inception(x)\n",
    "        x = self.inception2(x)\n",
    "\n",
    "        # Attention Block\n",
    "        x = self.attention2(x)\n",
    "\n",
    "        # Gated Residual Block\n",
    "        x = self.gated_res(x)\n",
    "\n",
    "        # Attention Block\n",
    "        x = self.attention3(x)\n",
    "\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.activation(self.bn_fc1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(self.bn_fc2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(self.bn_fc3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(self.bn_fc4(self.fc4(x)))\n",
    "\n",
    "        metadata = self.activation(self.metadata_bn1(self.metadata_fc1(metadata)))\n",
    "        metadata = self.dropout(metadata)\n",
    "        metadata = self.activation(self.metadata_bn2(self.metadata_fc2(metadata)))\n",
    "        metadata = self.dropout(metadata)\n",
    "        metadata = self.activation(self.metadata_bn3(self.metadata_fc3(metadata)))\n",
    "        metadata = self.dropout(metadata)\n",
    "        metadata = self.activation(self.metadata_bn4(self.metadata_fc4(metadata)))\n",
    "\n",
    "        x = torch.cat([x, metadata], dim=1)\n",
    "\n",
    "        x = self.final_fc(x)\n",
    "        # Apply sigmoid to ensure output is between 0 and 1\n",
    "        x = self.final_activation(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (images, metadata), targets = batch\n",
    "        outputs = self(images, metadata)\n",
    "        loss = self.loss(outputs, targets)  # targets is already one-hot encoded\n",
    "        # Get the probability of the positive class\n",
    "        pos_probs = outputs[:, 1].float().cpu()\n",
    "\n",
    "        # Convert one-hot encoded targets to binary labels\n",
    "        targets_binary = targets[:, 1].int().cpu()\n",
    "        rocauc = self.auroc(pos_probs, targets_binary)  # Use class 1 probability\n",
    "\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        self.log(\n",
    "            \"train_pAUC\",\n",
    "            rocauc,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        (images, metadata), targets = batch\n",
    "        outputs = self(images, metadata)\n",
    "        loss = self.loss(outputs, targets)  # targets is already one-hot encoded\n",
    "        # Get the probability of the positive class\n",
    "        pos_probs = outputs[:, 1].float().cpu()\n",
    "\n",
    "        # Convert one-hot encoded targets to binary labels\n",
    "        targets_binary = targets[:, 1].int().cpu()\n",
    "        rocauc = self.auroc(pos_probs, targets_binary)\n",
    "\n",
    "        # Use class 1 probability\n",
    "\n",
    "        self.log(\n",
    "            \"val_loss\",\n",
    "            loss,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        self.log(\n",
    "            \"val_pAUC\",\n",
    "            rocauc,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        (images, metadata), targets = batch\n",
    "        outputs = self(images, metadata)\n",
    "        loss = self.loss(outputs, targets)  # targets is already one-hot encoded\n",
    "\n",
    "        # Get the probability of the positive class\n",
    "        pos_probs = outputs[:, 1].float().cpu()\n",
    "\n",
    "        # Convert one-hot encoded targets to binary labels\n",
    "        targets_binary = targets[:, 1].int().cpu()\n",
    "        rocauc = self.auroc(pos_probs, targets_binary)\n",
    "\n",
    "        self.log(\n",
    "            \"test_loss\",\n",
    "            loss,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        self.log(\n",
    "            \"test_pAUC\",\n",
    "            rocauc,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.NAdam(\n",
    "            self.parameters(), lr=0.001, momentum_decay=0.5, weight_decay=1e-5\n",
    "        )\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"train_loss\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import joblib\n",
    "import hashlib\n",
    "\n",
    "\n",
    "def prepare_df(\n",
    "    df: pd.DataFrame,\n",
    "    is_training=True,\n",
    "):\n",
    "    print(\"Preparing DataFrame...\")\n",
    "    df_hash = hashlib.md5(pd.util.hash_pandas_object(df).values).hexdigest()\n",
    "    cache_dir = \"./cache\"\n",
    "    param_string = f\"{is_training}\"\n",
    "    cache_file = os.path.join(cache_dir, f\"prepared_df_{df_hash}_{param_string}.joblib\")\n",
    "\n",
    "    # Check if cached version exists\n",
    "    if os.path.exists(cache_file):\n",
    "        print(\"Loading cached prepared DataFrame...\")\n",
    "        return joblib.load(cache_file)\n",
    "    start_time = time.time()\n",
    "\n",
    "    drop_columns_train = [\n",
    "        \"lesion_id\",\n",
    "        \"iddx_full\",\n",
    "        \"iddx_1\",\n",
    "        \"iddx_2\",\n",
    "        \"iddx_3\",\n",
    "        \"iddx_4\",\n",
    "        \"iddx_5\",\n",
    "        \"mel_mitotic_index\",\n",
    "        \"mel_thick_mm\",\n",
    "        \"tbp_lv_dnn_lesion_confidence\",\n",
    "    ]\n",
    "    drop_columns_test = [\"attribution\", \"copyright_license\"]\n",
    "\n",
    "    if is_training:\n",
    "        df.drop(drop_columns_train, axis=1, inplace=True)\n",
    "    df.drop(drop_columns_test, axis=1, inplace=True)\n",
    "    target_columns = [\"target\"] if is_training else []\n",
    "    X = df.drop(target_columns + [\"isic_id\"], axis=1)\n",
    "    y = torch.tensor(df[\"target\"].values, dtype=torch.int8) if is_training else None\n",
    "\n",
    "    # Separate features by type\n",
    "    integer_features = X.select_dtypes(include=[\"int64\", \"int32\", \"int16\"]).columns\n",
    "    float_features = X.select_dtypes(include=[\"float64\", \"float32\", \"float16\"]).columns\n",
    "    categorical_features = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "    # Handle NaN values and type conversions\n",
    "    for feature in float_features:\n",
    "        X[feature] = X[feature].fillna(X[feature].mean()).astype(\"float32\")\n",
    "\n",
    "    for feature in integer_features:\n",
    "        X[feature] = X[feature].fillna(X[feature].median()).astype(\"int32\")\n",
    "\n",
    "    for feature in categorical_features:\n",
    "        X[feature] = X[feature].astype(str).fillna(\"Unknown\")\n",
    "        X[feature] = pd.Categorical(X[feature]).codes\n",
    "\n",
    "    # Standardize all numeric features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
    "\n",
    "    X_final = X_scaled\n",
    "\n",
    "    # Final check for any remaining NaN values\n",
    "    assert (\n",
    "        not X_final.isnull().any().any()\n",
    "    ), \"There are still NaN values in the processed data\"\n",
    "\n",
    "    print(\"Data shape after preprocessing:\", X_final.shape)\n",
    "    print(\"Number of NaN values after preprocessing:\", X_final.isnull().sum().sum())\n",
    "\n",
    "    if is_training:\n",
    "        print(\"Class distribution:\")\n",
    "        print(df[\"target\"].value_counts(normalize=True))\n",
    "\n",
    "    print(f\"DataFrame prepared in {time.time() - start_time:.2f} seconds\")\n",
    "    print(f\"Metadata Shape: {X_final.shape}\")\n",
    "\n",
    "    # Cache the results\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    joblib.dump((X_final, y, df[\"isic_id\"]), cache_file)\n",
    "    return X_final, y, df[\"isic_id\"]\n",
    "\n",
    "\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, hdf5_path, metadata_df, is_training=True, transform=None):\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.metadata_df = metadata_df\n",
    "        self.is_training = is_training\n",
    "        self.transform = transform\n",
    "        self.X, self.y, self.image_names = prepare_df(metadata_df, is_training)\n",
    "        self.metadata_shape = self.X.shape\n",
    "        self.train_transform = get_transforms(is_training=True)\n",
    "        self.test_transform = get_transforms(is_training=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, tuple):\n",
    "            idx, augment = idx\n",
    "        else:\n",
    "            augment = False\n",
    "\n",
    "        isic_id = self.image_names[idx]\n",
    "        metadata = torch.tensor(self.X.iloc[idx].values, dtype=torch.float32)\n",
    "\n",
    "        with h5py.File(self.hdf5_path, \"r\") as hdf:\n",
    "            image_data = hdf[str(isic_id)][()]\n",
    "            image = Image.open(io.BytesIO(image_data))\n",
    "\n",
    "        if self.is_training and augment:\n",
    "            image = self.train_transform(image)\n",
    "        elif self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.is_training:\n",
    "            target = self.y[idx]\n",
    "            target_long = target.long()\n",
    "            del target\n",
    "            target_one_hot = nn.functional.one_hot(target_long, num_classes=2).float()\n",
    "            return (image, metadata), target_one_hot\n",
    "        else:\n",
    "            return (image, metadata), isic_id\n",
    "\n",
    "\n",
    "# Create separate transforms for training and validation\n",
    "def get_transforms(is_training=True):\n",
    "    # Define augmentation parameters\n",
    "    ROTATION_RANGE = 90\n",
    "    BRIGHTNESS_RANGE = (0.9, 1.1)\n",
    "    CONTRAST_RANGE = (0.9, 1.1)\n",
    "    SATURATION_RANGE = (0.9, 1.1)\n",
    "    HUE_RANGE = (-0.001, 0.001)\n",
    "    base_transforms = [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((139, 139), antialias=True),\n",
    "    ]\n",
    "\n",
    "    if is_training:\n",
    "        train_transforms = [\n",
    "            transforms.RandomResizedCrop(\n",
    "                size=(139, 139), scale=(0.99, 1.01), antialias=True\n",
    "            ),\n",
    "            transforms.RandomRotation(\n",
    "                degrees=ROTATION_RANGE,\n",
    "                interpolation=transforms.InterpolationMode.BICUBIC,\n",
    "            ),\n",
    "            transforms.ColorJitter(\n",
    "                brightness=BRIGHTNESS_RANGE,\n",
    "                contrast=CONTRAST_RANGE,\n",
    "                saturation=SATURATION_RANGE,\n",
    "                hue=HUE_RANGE,\n",
    "            ),\n",
    "        ]\n",
    "        return transforms.Compose(train_transforms + base_transforms)\n",
    "    else:\n",
    "        return transforms.Compose(base_transforms)\n",
    "\n",
    "\n",
    "class ISICDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_hdf5_path: str,\n",
    "        test_hdf5_path: str,\n",
    "        train_metadata_df: pd.DataFrame,\n",
    "        test_metadata_df: pd.DataFrame,\n",
    "        batch_size: int = 32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_hdf5_path = train_hdf5_path\n",
    "        self.test_hdf5_path = test_hdf5_path\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.train_metadata_df = train_metadata_df\n",
    "        self.test_metadata_df = test_metadata_df\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        full_dataset = ISICDataset(\n",
    "            self.train_hdf5_path,\n",
    "            self.train_metadata_df,\n",
    "            True,\n",
    "            transform=get_transforms(is_training=True),\n",
    "        )\n",
    "        self.metadata_shape = full_dataset.metadata_shape\n",
    "        \n",
    "        # Get targets for stratification\n",
    "        targets = self.train_metadata_df[\"target\"].values\n",
    "        balanced_indices = self.balance_dataset(np.arange(len(full_dataset)), targets)\n",
    "        \n",
    "        # Extract actual indices and augmentation flags\n",
    "        balanced_indices, augmentation_flags = zip(*balanced_indices)\n",
    "        balanced_indices = np.array(balanced_indices)\n",
    "        \n",
    "        augmentation_flags = np.array(augmentation_flags)\n",
    "        balanced_targets = targets[balanced_indices]\n",
    "\n",
    "        print(f\"Unique indices: {np.unique(balanced_indices)}\")\n",
    "        print(f\"Unique targets: {np.unique(balanced_targets)}\")\n",
    "        \n",
    "        print(len(balanced_indices))\n",
    "        print(len(balanced_targets))\n",
    "        \n",
    "        unique, counts = np.unique(balanced_targets, return_counts=True)\n",
    "        print(f\"Setup Count: {dict(zip(unique, counts))}\")\n",
    "        # Perform stratified split\n",
    "        train_indices, temp_indices, train_targets, temp_targets = train_test_split(\n",
    "            balanced_indices,\n",
    "            balanced_targets,\n",
    "            test_size=0.2,\n",
    "            # stratify=balanced_targets,\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        val_indices, test_indices, val_targets, test_targets = train_test_split(\n",
    "            temp_indices,\n",
    "            temp_targets,\n",
    "            test_size=0.5,\n",
    "            # stratify=temp_targets,\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        # Create subset datasets\n",
    "        if stage in [\"fit\", \"validate\", \"test\"]:\n",
    "            self.train_dataset = Subset(full_dataset, train_indices)\n",
    "            self.val_dataset = Subset(full_dataset, val_indices)\n",
    "            self.test_dataset = Subset(full_dataset, test_indices)\n",
    "\n",
    "        # Check for class balance\n",
    "        self._check_class_balance(train_targets.flatten(), \"Train\")\n",
    "        self._check_class_balance(val_targets.flatten(), \"Validation\")\n",
    "        self._check_class_balance(test_targets.flatten(), \"Test\")\n",
    "\n",
    "        print(f\"Length of full_dataset: {len(full_dataset)}\")\n",
    "        print(\n",
    "            f\"Length of train_indices: {len(train_indices)}, max index: {max(train_indices)}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Length of val_indices: {len(val_indices)}, max index: {max(val_indices)}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Length of test_indices: {len(test_indices)}, max index: {max(test_indices)}\"\n",
    "        )\n",
    "\n",
    "    def balance_dataset(self, indices, targets):\n",
    "        np.random.seed(42)\n",
    "        positive_indices = indices[targets == 1]\n",
    "        negative_indices = indices[targets == 0]\n",
    "\n",
    "        num_positive_samples = len(positive_indices)\n",
    "        num_negative_samples = len(negative_indices)\n",
    "\n",
    "        print(f\"Number of Positive Samples: {num_positive_samples}\")\n",
    "        print(f\"Number of Negative Samples: {num_negative_samples}\")\n",
    "\n",
    "        # Determine the number of samples for each class\n",
    "        num_samples = int(np.mean([num_positive_samples, num_negative_samples]))//10\n",
    "\n",
    "        # Upsample positive indices\n",
    "        upsampled_positive_indices = np.random.choice(\n",
    "            positive_indices, size=num_samples // 2, replace=True\n",
    "        )\n",
    "\n",
    "        # Downsample negative indices\n",
    "        downsampled_negative_indices = np.random.choice(\n",
    "            negative_indices, size=num_samples // 2, replace=False\n",
    "        )\n",
    "\n",
    "        # Add augmentation flag\n",
    "        balanced_indices = [(idx, True) for idx in upsampled_positive_indices] + [\n",
    "            (idx, False) for idx in downsampled_negative_indices\n",
    "        ]\n",
    "\n",
    "        np.random.shuffle(balanced_indices)\n",
    "\n",
    "        print(f\"Length of Balanced Positive Indices: {len(upsampled_positive_indices)}\")\n",
    "        print(\n",
    "            f\"Length of Balanced Negative Indices: {len(downsampled_negative_indices)}\"\n",
    "        )\n",
    "\n",
    "        return balanced_indices\n",
    "\n",
    "    def _check_class_balance(self, targets, split_name):\n",
    "        class_counts = np.bincount(targets)\n",
    "        print(\n",
    "            f\"{split_name} class distribution: {class_counts / len(targets)}, {len(targets)}\"\n",
    "        )\n",
    "        if len(class_counts) < 2 or min(class_counts) == 0:\n",
    "            raise ValueError(f\"Imbalanced classes in {split_name} split\")\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        data_loader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=16,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        print(f\"Number of batches in train_loader: {len(data_loader)}\")\n",
    "        return data_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        data_loader = DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        print(f\"Number of batches in val_loader: {len(data_loader)}\")\n",
    "        return data_loader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "\n",
    "        data_loader = DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        print(f\"Number of batches in test_loader: {len(data_loader)}\")\n",
    "        return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43727/2539756025.py:5: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_metadata_df = pd.read_csv(\"train-metadata.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "img_height, img_width = 139, 139\n",
    "\n",
    "# Load metadata\n",
    "train_metadata_df = pd.read_csv(\"train-metadata.csv\")\n",
    "test_metadata_df = pd.read_csv(\"test-metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43727/2342527339.py:266: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = GradScaler()\n",
      "/home/pupperemeritus/miniconda3/envs/isic/lib/python3.12/site-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing DataFrame...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pupperemeritus/miniconda3/envs/isic/lib/python3.12/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached prepared DataFrame...\n",
      "Number of Positive Samples: 393\n",
      "Number of Negative Samples: 400666\n",
      "Length of Balanced Positive Indices: 10026\n",
      "Length of Balanced Negative Indices: 10026\n",
      "Unique indices: [    81    237    261 ... 400922 400982 400984]\n",
      "Unique targets: [0 1]\n",
      "20052\n",
      "20052\n",
      "Setup Count: {np.int64(0): np.int64(10026), np.int64(1): np.int64(10026)}\n",
      "Train class distribution: [0.50090393 0.49909607], 16041\n",
      "Validation class distribution: [0.50573566 0.49426434], 2005\n",
      "Test class distribution: [0.48703888 0.51296112], 2006\n",
      "Length of full_dataset: 401059\n",
      "Length of train_indices: 16041, max index: 400982\n",
      "Length of val_indices: 2005, max index: 400922\n",
      "Length of test_indices: 2006, max index: 400984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pupperemeritus/miniconda3/envs/isic/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "   | Name             | Type               | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | conv1            | Conv2d             | 19.5 K | train\n",
      "1  | bn1              | BatchNorm2d        | 512    | train\n",
      "2  | activation       | Hardswish          | 0      | train\n",
      "3  | inv_res_blocks   | ModuleList         | 2.2 M  | train\n",
      "4  | dense_block      | DenseBlock         | 2.0 M  | train\n",
      "5  | transition       | TransitionLayer    | 351 K  | train\n",
      "6  | attention        | AttentionBlock     | 215 K  | train\n",
      "7  | avg_pool         | AvgPool2d          | 0      | train\n",
      "8  | inception        | InceptionBlock     | 406 K  | train\n",
      "9  | inception2       | InceptionBlock     | 526 K  | train\n",
      "10 | attention2       | AttentionBlock     | 280 K  | train\n",
      "11 | gated_res        | GatedResidualBlock | 1.8 M  | train\n",
      "12 | attention3       | AttentionBlock     | 263 K  | train\n",
      "13 | global_avg_pool  | AdaptiveAvgPool2d  | 0      | train\n",
      "14 | flatten          | Flatten            | 0      | train\n",
      "15 | fc1              | Linear             | 1.1 M  | train\n",
      "16 | bn_fc1           | BatchNorm1d        | 8.2 K  | train\n",
      "17 | fc2              | Linear             | 8.4 M  | train\n",
      "18 | bn_fc2           | BatchNorm1d        | 4.1 K  | train\n",
      "19 | fc3              | Linear             | 1.0 M  | train\n",
      "20 | bn_fc3           | BatchNorm1d        | 1.0 K  | train\n",
      "21 | fc4              | Linear             | 65.7 K | train\n",
      "22 | bn_fc4           | BatchNorm1d        | 256    | train\n",
      "23 | dropout          | Dropout            | 0      | train\n",
      "24 | metadata_fc1     | Linear             | 172 K  | train\n",
      "25 | metadata_bn1     | BatchNorm1d        | 8.2 K  | train\n",
      "26 | metadata_fc2     | Linear             | 4.2 M  | train\n",
      "27 | metadata_bn2     | BatchNorm1d        | 2.0 K  | train\n",
      "28 | metadata_fc3     | Linear             | 524 K  | train\n",
      "29 | metadata_bn3     | BatchNorm1d        | 1.0 K  | train\n",
      "30 | metadata_fc4     | Linear             | 65.7 K | train\n",
      "31 | metadata_bn4     | BatchNorm1d        | 256    | train\n",
      "32 | final_fc         | Linear             | 514    | train\n",
      "33 | final_activation | Sigmoid            | 0      | train\n",
      "34 | loss             | CrossEntropyLoss   | 0      | train\n",
      "35 | auroc            | PartialAUROC       | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "23.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.7 M    Total params\n",
      "94.654    Total estimated model params size (MB)\n",
      "477       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]Number of batches in val_loader: 32\n",
      "Number of batches in train_loader: 251                                     \n",
      "Epoch 0: 100%|██████████| 251/251 [01:28<00:00,  2.85it/s, v_num=141, train_loss_step=0.432, train_pAUC_step=0.174, val_loss=0.416, val_pAUC=0.172, train_loss_epoch=0.479, train_pAUC_epoch=0.151]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 63: 'val_loss' reached 0.41571 (best 0.41571), saving model to '/home/pupperemeritus/DL/isic-2024-challenge/checkpoints/version_141/gurunet-epoch=00-val_loss=0.41571.ckpt' as top 3\n",
      "Epoch 0, global step 63: 'val_pAUC' reached 0.17182 (best 0.17182), saving model to '/home/pupperemeritus/DL/isic-2024-challenge/checkpoints/version_141/gurunet-epoch=00-val_pAUC=0.17182.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  75%|███████▍  | 187/251 [00:59<00:20,  3.15it/s, v_num=141, train_loss_step=0.427, train_pAUC_step=0.176, val_loss=0.416, val_pAUC=0.172, train_loss_epoch=0.479, train_pAUC_epoch=0.151] "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ.setdefault(\"CUDA_LAUNCH_BLOCKING\", \"1\")\n",
    "torch.cuda.memory.empty_cache()\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"gurunet_model\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"checkpoints/version_{logger.version}\",\n",
    "    filename=\"gurunet-{epoch:02d}-{val_loss:.5f}\",\n",
    "    save_top_k=3,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    verbose=True,\n",
    ")\n",
    "checkpoint_callback_2 = ModelCheckpoint(\n",
    "    dirpath=f\"checkpoints/version_{logger.version}\",\n",
    "    filename=\"gurunet-{epoch:02d}-{val_pAUC:.5f}\",\n",
    "    save_top_k=3,\n",
    "    monitor=\"val_pAUC\",\n",
    "    mode=\"max\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_pAUC\", patience=15, mode=\"min\")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\", log_momentum=True)\n",
    "\n",
    "# Initialize your data module\n",
    "data_module = ISICDataModule(\n",
    "    \"train-image.hdf5\",\n",
    "    \"test-image.hdf5\",\n",
    "    train_metadata_df,\n",
    "    test_metadata_df,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize your model\n",
    "model = GuruNet(\n",
    "    input_shape=(139, 139, 3),\n",
    "    metadata_shape=(None, 37),\n",
    "    classes=2,\n",
    ")\n",
    "# Initialize a trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=epochs,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    callbacks=[\n",
    "        checkpoint_callback,\n",
    "        checkpoint_callback_2,\n",
    "        early_stop_callback,\n",
    "        lr_monitor,\n",
    "    ],\n",
    "    logger=logger,\n",
    "    precision=\"16\",\n",
    "    enable_progress_bar=True,\n",
    "    enable_checkpointing=True,\n",
    "    accumulate_grad_batches=4,\n",
    "    profiler=\"simple\",\n",
    "    min_epochs=50\n",
    ")\n",
    "skip_training = False\n",
    "if not skip_training:\n",
    "    # Train the model\n",
    "    trainer.fit(model, data_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing DataFrame...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at checkpoints/version_135/gurunet-epoch=48-val_pAUC=0.18755.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached prepared DataFrame...\n",
      "Number of Positive Samples: 393\n",
      "Number of Negative Samples: 400666\n",
      "Length of Balanced Positive Indices: 10026\n",
      "Length of Balanced Negative Indices: 10026\n",
      "Unique indices: [    81    237    261 ... 400922 400982 400984]\n",
      "Unique targets: [0 1]\n",
      "20052\n",
      "20052\n",
      "Setup Count: {0: 10026, 1: 10026}\n",
      "Train class distribution: [0.50090393 0.49909607], 16041\n",
      "Validation class distribution: [0.50573566 0.49426434], 2005\n",
      "Test class distribution: [0.48703888 0.51296112], 2006\n",
      "Length of full_dataset: 401059\n",
      "Length of train_indices: 16041, max index: 400982\n",
      "Length of val_indices: 2005, max index: 400922\n",
      "Length of test_indices: 2006, max index: 400984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at checkpoints/version_135/gurunet-epoch=48-val_pAUC=0.18755.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in test_loader: 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8171bf965dec4dfda65c18c3c09f3762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_loss_epoch      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34257519245147705    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_pAUC_epoch      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18955282866954803    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34257519245147705   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_pAUC_epoch     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18955282866954803   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST Profiler Report\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                               \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                                \t|  -              \t|  554362         \t|  5624.9         \t|  100 %          \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                                   \t|  68.883         \t|  50             \t|  3444.2         \t|  61.23          \t|\n",
      "|  run_training_batch                                                                                                                                                   \t|  0.23981        \t|  12550          \t|  3009.6         \t|  53.504         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                              \t|  0.13463        \t|  12550          \t|  1689.6         \t|  30.037         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                         \t|  0.10075        \t|  12550          \t|  1264.5         \t|  22.479         \t|\n",
      "|  [LightningModule]GuruNet.optimizer_step                                                                                                                              \t|  0.25048        \t|  3150           \t|  789.01         \t|  14.027         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.validation_step                                                                                                                       \t|  0.090704       \t|  1602           \t|  145.31         \t|  2.5833         \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                           \t|  0.006552       \t|  12550          \t|  82.228         \t|  1.4618         \t|\n",
      "|  [_EvaluationLoop].val_next                                                                                                                                           \t|  0.037451       \t|  1603           \t|  60.034         \t|  1.0673         \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                         \t|  0.0010314      \t|  12550          \t|  12.944         \t|  0.23011        \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end       \t|  0.23968        \t|  50             \t|  11.984         \t|  0.21306        \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end       \t|  0.2383         \t|  50             \t|  11.915         \t|  0.21182        \t|\n",
      "|  [Strategy]SingleDeviceStrategy.test_step                                                                                                                             \t|  0.095838       \t|  64             \t|  6.1336         \t|  0.10904        \t|\n",
      "|  [_EvaluationLoop].test_next                                                                                                                                          \t|  0.046869       \t|  64             \t|  2.9996         \t|  0.053326       \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                       \t|  0.00019407     \t|  14216          \t|  2.7588         \t|  0.049047       \t|\n",
      "|  [LightningModule]GuruNet.optimizer_zero_grad                                                                                                                         \t|  0.00082725     \t|  3150           \t|  2.6058         \t|  0.046327       \t|\n",
      "|  [LightningModule]GuruNet.transfer_batch_to_device                                                                                                                    \t|  0.00015226     \t|  14216          \t|  2.1645         \t|  0.03848        \t|\n",
      "|  [LightningDataModule]ISICDataModule.setup                                                                                                                            \t|  0.69783        \t|  3              \t|  2.0935         \t|  0.037218       \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_end                                                                                                                    \t|  0.00060814     \t|  1602           \t|  0.97425        \t|  0.01732        \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_start                                                                                                                        \t|  0.0079689      \t|  51             \t|  0.40641        \t|  0.0072252      \t|\n",
      "|  [LightningModule]GuruNet.on_validation_model_eval                                                                                                                    \t|  0.0075428      \t|  51             \t|  0.38468        \t|  0.0068389      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end       \t|  1.6908e-05     \t|  12550          \t|  0.21219        \t|  0.0037723      \t|\n",
      "|  [LightningModule]GuruNet.on_validation_model_train                                                                                                                   \t|  0.0024705      \t|  51             \t|  0.12599        \t|  0.0022399      \t|\n",
      "|  [LightningModule]GuruNet.configure_gradient_clipping                                                                                                                 \t|  2.1383e-05     \t|  3150           \t|  0.067357       \t|  0.0011975      \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_start                                                                                                                  \t|  3.8799e-05     \t|  1602           \t|  0.062155       \t|  0.001105       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end       \t|  4.2402e-06     \t|  12550          \t|  0.053214       \t|  0.00094604     \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_batch_end                                                                                                                          \t|  0.00072461     \t|  64             \t|  0.046375       \t|  0.00082446     \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_batch_start                                                                                                                   \t|  3.2964e-06     \t|  12550          \t|  0.04137        \t|  0.00073548     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_after_backward                                                                                      \t|  3.0059e-06     \t|  12550          \t|  0.037724       \t|  0.00067066     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_train_epoch_end                                                                                     \t|  0.00073596     \t|  50             \t|  0.036798       \t|  0.00065419     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                       \t|  0.00057628     \t|  50             \t|  0.028814       \t|  0.00051226     \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                            \t|  2.1279e-06     \t|  12550          \t|  0.026705       \t|  0.00047476     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_end                                                                                                                          \t|  0.00048874     \t|  51             \t|  0.024926       \t|  0.00044313     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_train_batch_end                                                                                     \t|  1.6874e-06     \t|  12550          \t|  0.021177       \t|  0.00037649     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_before_backward                                                                                     \t|  1.5972e-06     \t|  12550          \t|  0.020045       \t|  0.00035636     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_train_batch_start                                                                                   \t|  1.484e-06      \t|  12550          \t|  0.018624       \t|  0.0003311      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                         \t|  0.00036174     \t|  50             \t|  0.018087       \t|  0.00032155     \t|\n",
      "|  [LightningModule]GuruNet.on_test_model_eval                                                                                                                          \t|  0.0085921      \t|  2              \t|  0.017184       \t|  0.0003055      \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_start                                                                                                                              \t|  0.0063566      \t|  2              \t|  0.012713       \t|  0.00022602     \t|\n",
      "|  [Callback]LearningRateMonitor.on_after_backward                                                                                                                      \t|  1.0027e-06     \t|  12550          \t|  0.012584       \t|  0.00022372     \t|\n",
      "|  [LightningModule]GuruNet.on_before_batch_transfer                                                                                                                    \t|  8.77e-07       \t|  14216          \t|  0.012467       \t|  0.00022164     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward        \t|  9.7673e-07     \t|  12550          \t|  0.012258       \t|  0.00021792     \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                          \t|  8.6856e-07     \t|  12550          \t|  0.0109         \t|  0.00019379     \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_batch_end                                                                                                                     \t|  8.2406e-07     \t|  12550          \t|  0.010342       \t|  0.00018386     \t|\n",
      "|  [LightningModule]GuruNet.on_after_batch_transfer                                                                                                                     \t|  7.2416e-07     \t|  14216          \t|  0.010295       \t|  0.00018302     \t|\n",
      "|  [LightningModule]GuruNet.on_after_backward                                                                                                                           \t|  8.167e-07      \t|  12550          \t|  0.01025        \t|  0.00018222     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start     \t|  8.1089e-07     \t|  12550          \t|  0.010177       \t|  0.00018092     \t|\n",
      "|  [LightningModule]GuruNet.on_train_batch_start                                                                                                                        \t|  7.9306e-07     \t|  12550          \t|  0.0099529      \t|  0.00017694     \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                             \t|  7.8884e-07     \t|  12550          \t|  0.0099         \t|  0.000176       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                       \t|  7.8214e-07     \t|  12550          \t|  0.0098159      \t|  0.00017451     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward        \t|  7.8146e-07     \t|  12550          \t|  0.0098074      \t|  0.00017435     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                                  \t|  7.4808e-07     \t|  12550          \t|  0.0093884      \t|  0.00016691     \t|\n",
      "|  [Callback]LearningRateMonitor.on_before_backward                                                                                                                     \t|  7.2954e-07     \t|  12550          \t|  0.0091558      \t|  0.00016277     \t|\n",
      "|  [LightningModule]GuruNet.on_train_batch_end                                                                                                                          \t|  7.2106e-07     \t|  12550          \t|  0.0090493      \t|  0.00016088     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward       \t|  6.9732e-07     \t|  12550          \t|  0.0087514      \t|  0.00015558     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward       \t|  6.5285e-07     \t|  12550          \t|  0.0081932      \t|  0.00014566     \t|\n",
      "|  [LightningModule]GuruNet.on_before_backward                                                                                                                          \t|  6.4635e-07     \t|  12550          \t|  0.0081117      \t|  0.00014421     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start     \t|  6.3728e-07     \t|  12550          \t|  0.0079978      \t|  0.00014218     \t|\n",
      "|  [LightningModule]GuruNet.on_test_model_train                                                                                                                         \t|  0.0038508      \t|  2              \t|  0.0077015      \t|  0.00013692     \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                          \t|  6.127e-07      \t|  12550          \t|  0.0076894      \t|  0.0001367      \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                         \t|  5.8243e-07     \t|  12550          \t|  0.0073095      \t|  0.00012995     \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                                  \t|  0.0067668      \t|  1              \t|  0.0067668      \t|  0.0001203      \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                            \t|  5.2212e-07     \t|  12550          \t|  0.0065526      \t|  0.00011649     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_before_zero_grad                                                                                    \t|  2.0178e-06     \t|  3150           \t|  0.0063561      \t|  0.000113       \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_before_optimizer_step                                                                               \t|  1.7197e-06     \t|  3150           \t|  0.0054171      \t|  9.6305e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_epoch_start                                                                                                                   \t|  9.9783e-05     \t|  50             \t|  0.0049891      \t|  8.8696e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                             \t|  0.0039682      \t|  1              \t|  0.0039682      \t|  7.0547e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_start                                                                                                                      \t|  0.0038805      \t|  1              \t|  0.0038805      \t|  6.8987e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_end                                                                                                                       \t|  2.0216e-06     \t|  1602           \t|  0.0032386      \t|  5.7576e-05     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_validation_batch_end                                                                                \t|  1.9877e-06     \t|  1602           \t|  0.0031843      \t|  5.661e-05      \t|\n",
      "|  [LightningModule]GuruNet.on_before_zero_grad                                                                                                                         \t|  9.9838e-07     \t|  3150           \t|  0.0031449      \t|  5.591e-05      \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                                      \t|  8.9307e-07     \t|  3150           \t|  0.0028132      \t|  5.0013e-05     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_validation_batch_start                                                                              \t|  1.5347e-06     \t|  1602           \t|  0.0024587      \t|  4.371e-05      \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_batch_start                                                                                                                        \t|  3.8389e-05     \t|  64             \t|  0.0024569      \t|  4.3679e-05     \t|\n",
      "|  [LightningModule]GuruNet.lr_scheduler_step                                                                                                                           \t|  4.8473e-05     \t|  50             \t|  0.0024236      \t|  4.3087e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.on_before_optimizer_step                                                                                                               \t|  7.6683e-07     \t|  3150           \t|  0.0024155      \t|  4.2943e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.on_before_zero_grad                                                                                                                    \t|  7.5501e-07     \t|  3150           \t|  0.0023783      \t|  4.2281e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_end        \t|  4.1239e-05     \t|  51             \t|  0.0021032      \t|  3.739e-05      \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                        \t|  6.2298e-07     \t|  3150           \t|  0.0019624      \t|  3.4887e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad      \t|  6.0657e-07     \t|  3150           \t|  0.0019107      \t|  3.3968e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad      \t|  5.9892e-07     \t|  3150           \t|  0.0018866      \t|  3.354e-05      \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                                   \t|  5.9592e-07     \t|  3150           \t|  0.0018772      \t|  3.3372e-05     \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                           \t|  5.9023e-07     \t|  3150           \t|  0.0018592      \t|  3.3053e-05     \t|\n",
      "|  [LightningModule]GuruNet.on_before_optimizer_step                                                                                                                    \t|  5.6773e-07     \t|  3150           \t|  0.0017883      \t|  3.1793e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step \t|  5.5737e-07     \t|  3150           \t|  0.0017557      \t|  3.1213e-05     \t|\n",
      "|  [LightningModule]GuruNet.on_validation_batch_end                                                                                                                     \t|  1.0725e-06     \t|  1602           \t|  0.0017182      \t|  3.0546e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step \t|  5.3404e-07     \t|  3150           \t|  0.0016822      \t|  2.9907e-05     \t|\n",
      "|  [LightningModule]GuruNet.on_validation_batch_start                                                                                                                   \t|  8.8674e-07     \t|  1602           \t|  0.0014206      \t|  2.5255e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_end  \t|  7.8855e-07     \t|  1602           \t|  0.0012633      \t|  2.2458e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_start                                                                                                                     \t|  7.72e-07       \t|  1602           \t|  0.0012367      \t|  2.1987e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_batch_start                                                                                                              \t|  7.6142e-07     \t|  1602           \t|  0.0012198      \t|  2.1686e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_batch_end                                                                                                                \t|  7.5776e-07     \t|  1602           \t|  0.0012139      \t|  2.1581e-05     \t|\n",
      "|  [LightningModule]GuruNet.configure_optimizers                                                                                                                        \t|  0.0011666      \t|  1              \t|  0.0011666      \t|  2.074e-05      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_start\t|  6.4563e-07     \t|  1602           \t|  0.0010343      \t|  1.8388e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_end  \t|  6.1227e-07     \t|  1602           \t|  0.00098086     \t|  1.7438e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_start\t|  5.922e-07      \t|  1602           \t|  0.0009487      \t|  1.6866e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_start                                                                                                                           \t|  8.0206e-06     \t|  51             \t|  0.00040905     \t|  7.2721e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_end                                                                                                                                \t|  0.00019581     \t|  2              \t|  0.00039163     \t|  6.9623e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_validation_start                                                                                    \t|  7.3278e-06     \t|  51             \t|  0.00037372     \t|  6.644e-06      \t|\n",
      "|  [LightningDataModule]ISICDataModule.test_dataloader                                                                                                                  \t|  0.00018314     \t|  2              \t|  0.00036628     \t|  6.5117e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_end        \t|  6.3037e-06     \t|  51             \t|  0.00032149     \t|  5.7154e-06     \t|\n",
      "|  [LightningDataModule]ISICDataModule.train_dataloader                                                                                                                 \t|  0.00028383     \t|  1              \t|  0.00028383     \t|  5.0458e-06     \t|\n",
      "|  [LightningModule]GuruNet.on_validation_epoch_start                                                                                                                   \t|  5.1013e-06     \t|  51             \t|  0.00026016     \t|  4.6252e-06     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_start                                                                                                                   \t|  4.9815e-06     \t|  51             \t|  0.00025406     \t|  4.5166e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_validation_end                                                                                      \t|  4.8034e-06     \t|  51             \t|  0.00024497     \t|  4.3552e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_train_epoch_start                                                                                   \t|  4.8103e-06     \t|  50             \t|  0.00024052     \t|  4.2759e-06     \t|\n",
      "|  [LightningDataModule]ISICDataModule.val_dataloader                                                                                                                   \t|  0.00022826     \t|  1              \t|  0.00022826     \t|  4.0581e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_start                                                                                                                    \t|  3.9883e-06     \t|  51             \t|  0.00020341     \t|  3.6161e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                               \t|  0.00018996     \t|  1              \t|  0.00018996     \t|  3.3772e-06     \t|\n",
      "|  [Callback]ModelSummary.on_test_batch_end                                                                                                                             \t|  2.9641e-06     \t|  64             \t|  0.0001897      \t|  3.3725e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_test_batch_end                                                                                      \t|  2.0161e-06     \t|  64             \t|  0.00012903     \t|  2.2939e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_test_batch_start                                                                                    \t|  1.653e-06      \t|  64             \t|  0.00010579     \t|  1.8808e-06     \t|\n",
      "|  [LightningDataModule]ISICDataModule.state_dict                                                                                                                       \t|  1.117e-06      \t|  67             \t|  7.484e-05      \t|  1.3305e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_save_checkpoint                                                                                     \t|  1.1021e-06     \t|  67             \t|  7.384e-05      \t|  1.3127e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_epoch_end                                                                                                                     \t|  1.4337e-06     \t|  50             \t|  7.1686e-05     \t|  1.2744e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_validation_epoch_end                                                                                \t|  1.3932e-06     \t|  51             \t|  7.1052e-05     \t|  1.2632e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_start      \t|  1.3498e-06     \t|  51             \t|  6.8841e-05     \t|  1.2239e-06     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                          \t|  1.3472e-06     \t|  50             \t|  6.7362e-05     \t|  1.1976e-06     \t|\n",
      "|  [Callback]ModelSummary.on_validation_end                                                                                                                             \t|  1.3133e-06     \t|  51             \t|  6.698e-05      \t|  1.1908e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_validation_epoch_start                                                                              \t|  1.2696e-06     \t|  51             \t|  6.4752e-05     \t|  1.1512e-06     \t|\n",
      "|  [LightningModule]GuruNet.on_test_batch_start                                                                                                                         \t|  1.0044e-06     \t|  64             \t|  6.4283e-05     \t|  1.1428e-06     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                            \t|  1.2714e-06     \t|  50             \t|  6.3571e-05     \t|  1.1302e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_start                                                                                                                         \t|  6.2301e-05     \t|  1              \t|  6.2301e-05     \t|  1.1076e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                    \t|  1.8687e-05     \t|  3              \t|  5.6061e-05     \t|  9.9665e-07     \t|\n",
      "|  [LightningModule]GuruNet.on_validation_start                                                                                                                         \t|  1.0614e-06     \t|  51             \t|  5.413e-05      \t|  9.6232e-07     \t|\n",
      "|  [LightningModule]GuruNet.on_test_batch_end                                                                                                                           \t|  8.2984e-07     \t|  64             \t|  5.311e-05      \t|  9.4419e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_start                                                                                                                  \t|  1.0375e-06     \t|  51             \t|  5.2911e-05     \t|  9.4065e-07     \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_end                                                                                                                      \t|  9.9176e-07     \t|  51             \t|  5.058e-05      \t|  8.9921e-07     \t|\n",
      "|  [Callback]LearningRateMonitor.on_test_batch_start                                                                                                                    \t|  7.2562e-07     \t|  64             \t|  4.644e-05      \t|  8.2561e-07     \t|\n",
      "|  [Callback]LearningRateMonitor.on_test_batch_end                                                                                                                      \t|  6.9719e-07     \t|  64             \t|  4.462e-05      \t|  7.9325e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_batch_end        \t|  6.8317e-07     \t|  64             \t|  4.3723e-05     \t|  7.773e-07      \t|\n",
      "|  [Callback]LearningRateMonitor.on_save_checkpoint                                                                                                                     \t|  6.4388e-07     \t|  67             \t|  4.314e-05      \t|  7.6694e-07     \t|\n",
      "|  [Callback]ModelSummary.on_test_batch_start                                                                                                                           \t|  6.6859e-07     \t|  64             \t|  4.279e-05      \t|  7.6072e-07     \t|\n",
      "|  [LightningModule]GuruNet.on_validation_end                                                                                                                           \t|  8.3333e-07     \t|  51             \t|  4.25e-05       \t|  7.5556e-07     \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                            \t|  6.1448e-07     \t|  67             \t|  4.117e-05      \t|  7.3192e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint       \t|  6.0449e-07     \t|  67             \t|  4.0501e-05     \t|  7.2002e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_end  \t|  7.7806e-07     \t|  51             \t|  3.9681e-05     \t|  7.0545e-07     \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_epoch_end                                                                                                                \t|  7.3784e-07     \t|  51             \t|  3.763e-05      \t|  6.6898e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_batch_start      \t|  5.75e-07       \t|  64             \t|  3.68e-05       \t|  6.5423e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_start      \t|  6.9651e-07     \t|  51             \t|  3.5522e-05     \t|  6.3151e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_batch_start      \t|  5.5344e-07     \t|  64             \t|  3.542e-05      \t|  6.2969e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_batch_end        \t|  5.4736e-07     \t|  64             \t|  3.5031e-05     \t|  6.2278e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start     \t|  6.7182e-07     \t|  50             \t|  3.3591e-05     \t|  5.9718e-07     \t|\n",
      "|  [LightningModule]GuruNet.on_train_epoch_start                                                                                                                        \t|  6.7102e-07     \t|  50             \t|  3.3551e-05     \t|  5.9647e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                         \t|  4.9091e-07     \t|  67             \t|  3.2891e-05     \t|  5.8473e-07     \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_epoch_start                                                                                                              \t|  6.0198e-07     \t|  51             \t|  3.0701e-05     \t|  5.458e-07      \t|\n",
      "|  [LightningModule]GuruNet.on_validation_epoch_end                                                                                                                     \t|  5.9924e-07     \t|  51             \t|  3.0561e-05     \t|  5.4331e-07     \t|\n",
      "|  [LightningModule]GuruNet.on_train_epoch_end                                                                                                                          \t|  6.0982e-07     \t|  50             \t|  3.0491e-05     \t|  5.4207e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint       \t|  4.5343e-07     \t|  67             \t|  3.038e-05      \t|  5.4009e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_end                                                                                                                    \t|  5.9157e-07     \t|  51             \t|  3.017e-05      \t|  5.3636e-07     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_end                                                                                                                     \t|  5.8022e-07     \t|  51             \t|  2.9591e-05     \t|  5.2607e-07     \t|\n",
      "|  [LightningModule]GuruNet.on_save_checkpoint                                                                                                                          \t|  4.3406e-07     \t|  67             \t|  2.9082e-05     \t|  5.1702e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start     \t|  5.7502e-07     \t|  50             \t|  2.8751e-05     \t|  5.1113e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_end  \t|  5.61e-07       \t|  51             \t|  2.8611e-05     \t|  5.0864e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_start\t|  5.3824e-07     \t|  51             \t|  2.745e-05      \t|  4.88e-07       \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_end                                                                                                                       \t|  5.2196e-07     \t|  51             \t|  2.662e-05      \t|  4.7325e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_start\t|  5.0571e-07     \t|  51             \t|  2.5791e-05     \t|  4.5851e-07     \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_start                                                                                                                     \t|  4.9627e-07     \t|  51             \t|  2.531e-05      \t|  4.4996e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                                      \t|  4.2833e-06     \t|  3              \t|  1.285e-05      \t|  2.2845e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                    \t|  3.96e-06       \t|  3              \t|  1.188e-05      \t|  2.112e-07      \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.setup                                                                                                  \t|  3.39e-06       \t|  3              \t|  1.017e-05      \t|  1.808e-07      \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_test_start                                                                                          \t|  4.295e-06      \t|  2              \t|  8.59e-06       \t|  1.5271e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.teardown                                                                                               \t|  2.4833e-06     \t|  3              \t|  7.45e-06       \t|  1.3245e-07     \t|\n",
      "|  [Callback]ModelSummary.on_test_start                                                                                                                                 \t|  2.995e-06      \t|  2              \t|  5.99e-06       \t|  1.0649e-07     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_test_start                                                                                                                         \t|  2.945e-06      \t|  2              \t|  5.89e-06       \t|  1.0471e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_end                                                                                                                        \t|  5.66e-06       \t|  1              \t|  5.66e-06       \t|  1.0062e-07     \t|\n",
      "|  [LightningModule]GuruNet.configure_callbacks                                                                                                                         \t|  1.8333e-06     \t|  3              \t|  5.5e-06        \t|  9.7779e-08     \t|\n",
      "|  [LightningModule]GuruNet.configure_sharded_model                                                                                                                     \t|  1.39e-06       \t|  3              \t|  4.17e-06       \t|  7.4134e-08     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_sanity_check_end                                                                                    \t|  4e-06          \t|  1              \t|  4e-06          \t|  7.1112e-08     \t|\n",
      "|  [LightningDataModule]ISICDataModule.teardown                                                                                                                         \t|  1.3267e-06     \t|  3              \t|  3.98e-06       \t|  7.0756e-08     \t|\n",
      "|  [Callback]LearningRateMonitor.setup                                                                                                                                  \t|  1.3167e-06     \t|  3              \t|  3.95e-06       \t|  7.0223e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start           \t|  3.81e-06       \t|  1              \t|  3.81e-06       \t|  6.7734e-08     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_train_start                                                                                         \t|  3.69e-06       \t|  1              \t|  3.69e-06       \t|  6.5601e-08     \t|\n",
      "|  [LightningModule]GuruNet.on_load_checkpoint                                                                                                                          \t|  1.6e-06        \t|  2              \t|  3.2e-06        \t|  5.6889e-08     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_fit_end                                                                                             \t|  3.12e-06       \t|  1              \t|  3.12e-06       \t|  5.5467e-08     \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                         \t|  9.2033e-07     \t|  3              \t|  2.761e-06      \t|  4.9085e-08     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_test_epoch_end                                                                                      \t|  1.38e-06       \t|  2              \t|  2.76e-06       \t|  4.9067e-08     \t|\n",
      "|  [LightningModule]GuruNet.setup                                                                                                                                       \t|  9.0667e-07     \t|  3              \t|  2.72e-06       \t|  4.8356e-08     \t|\n",
      "|  [Callback]LearningRateMonitor.teardown                                                                                                                               \t|  8.8e-07        \t|  3              \t|  2.64e-06       \t|  4.6934e-08     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_sanity_check_start                                                                                  \t|  2.471e-06      \t|  1              \t|  2.471e-06      \t|  4.3929e-08     \t|\n",
      "|  [Callback]ModelSummary.on_test_end                                                                                                                                   \t|  1.225e-06      \t|  2              \t|  2.45e-06       \t|  4.3556e-08     \t|\n",
      "|  [LightningDataModule]ISICDataModule.prepare_data                                                                                                                     \t|  7.9e-07        \t|  3              \t|  2.37e-06       \t|  4.2134e-08     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_train_end                                                                                           \t|  2.161e-06      \t|  1              \t|  2.161e-06      \t|  3.8418e-08     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_test_end                                                                                            \t|  1.005e-06      \t|  2              \t|  2.01e-06       \t|  3.5734e-08     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_start                                                                                                                         \t|  1.99e-06       \t|  1              \t|  1.99e-06       \t|  3.5378e-08     \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                                   \t|  6.3333e-07     \t|  3              \t|  1.9e-06        \t|  3.3778e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_start            \t|  8.75e-07       \t|  2              \t|  1.75e-06       \t|  3.1111e-08     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_test_epoch_start                                                                                    \t|  8.4e-07        \t|  2              \t|  1.68e-06       \t|  2.9867e-08     \t|\n",
      "|  [Callback]LearningRateMonitor.on_test_start                                                                                                                          \t|  8.25e-07       \t|  2              \t|  1.65e-06       \t|  2.9334e-08     \t|\n",
      "|  [Callback]LearningRateMonitor.on_test_epoch_end                                                                                                                      \t|  8.25e-07       \t|  2              \t|  1.65e-06       \t|  2.9334e-08     \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                                      \t|  5.3333e-07     \t|  3              \t|  1.6e-06        \t|  2.8445e-08     \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                                \t|  1.57e-06       \t|  1              \t|  1.57e-06       \t|  2.7911e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start           \t|  1.57e-06       \t|  1              \t|  1.57e-06       \t|  2.7911e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                 \t|  5.2e-07        \t|  3              \t|  1.56e-06       \t|  2.7733e-08     \t|\n",
      "|  [LightningModule]GuruNet.on_train_start                                                                                                                              \t|  1.54e-06       \t|  1              \t|  1.54e-06       \t|  2.7378e-08     \t|\n",
      "|  [LightningModule]GuruNet.on_test_start                                                                                                                               \t|  7.55e-07       \t|  2              \t|  1.51e-06       \t|  2.6845e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                 \t|  4.9667e-07     \t|  3              \t|  1.49e-06       \t|  2.6489e-08     \t|\n",
      "|  [LightningModule]GuruNet.teardown                                                                                                                                    \t|  4.9e-07        \t|  3              \t|  1.47e-06       \t|  2.6134e-08     \t|\n",
      "|  [LightningModule]GuruNet.prepare_data                                                                                                                                \t|  4.6667e-07     \t|  3              \t|  1.4e-06        \t|  2.4889e-08     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_pAUC', 'mode': 'min'}.on_fit_start                                                                                           \t|  1.4e-06        \t|  1              \t|  1.4e-06        \t|  2.4889e-08     \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                                  \t|  1.37e-06       \t|  1              \t|  1.37e-06       \t|  2.4356e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_end              \t|  6.65e-07       \t|  2              \t|  1.33e-06       \t|  2.3645e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start             \t|  1.28e-06       \t|  1              \t|  1.28e-06       \t|  2.2756e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_start            \t|  6.1e-07        \t|  2              \t|  1.22e-06       \t|  2.1689e-08     \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_end                                                                                                                           \t|  1.2e-06        \t|  1              \t|  1.2e-06        \t|  2.1334e-08     \t|\n",
      "|  [Callback]LearningRateMonitor.on_test_end                                                                                                                            \t|  5.85e-07       \t|  2              \t|  1.17e-06       \t|  2.08e-08       \t|\n",
      "|  [LightningModule]GuruNet.on_test_epoch_end                                                                                                                           \t|  5.85e-07       \t|  2              \t|  1.17e-06       \t|  2.08e-08       \t|\n",
      "|  [LightningModule]GuruNet.on_test_end                                                                                                                                 \t|  5.8e-07        \t|  2              \t|  1.16e-06       \t|  2.0622e-08     \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_epoch_start                                                                                                                        \t|  5.45e-07       \t|  2              \t|  1.09e-06       \t|  1.9378e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_epoch_end        \t|  5.4e-07        \t|  2              \t|  1.08e-06       \t|  1.92e-08       \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_test_end                                                                                                                           \t|  5.4e-07        \t|  2              \t|  1.08e-06       \t|  1.92e-08       \t|\n",
      "|  [LightningModule]GuruNet.on_test_epoch_start                                                                                                                         \t|  5.3e-07        \t|  2              \t|  1.06e-06       \t|  1.8845e-08     \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_epoch_end                                                                                                                          \t|  5.3e-07        \t|  2              \t|  1.06e-06       \t|  1.8845e-08     \t|\n",
      "|  [Callback]LearningRateMonitor.on_test_epoch_start                                                                                                                    \t|  5.1e-07        \t|  2              \t|  1.02e-06       \t|  1.8134e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_epoch_end        \t|  5.1e-07        \t|  2              \t|  1.02e-06       \t|  1.8134e-08     \t|\n",
      "|  [Callback]ModelSummary.on_test_epoch_start                                                                                                                           \t|  4.95e-07       \t|  2              \t|  9.9e-07        \t|  1.76e-08       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_end              \t|  4.7e-07        \t|  2              \t|  9.4e-07        \t|  1.6711e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_epoch_start      \t|  4.5e-07        \t|  2              \t|  9e-07          \t|  1.6e-08        \t|\n",
      "|  [Callback]ModelSummary.on_test_epoch_end                                                                                                                             \t|  4.4e-07        \t|  2              \t|  8.8e-07        \t|  1.5645e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_epoch_start      \t|  4.3e-07        \t|  2              \t|  8.6e-07        \t|  1.5289e-08     \t|\n",
      "|  [Callback]LearningRateMonitor.on_sanity_check_end                                                                                                                    \t|  8.4e-07        \t|  1              \t|  8.4e-07        \t|  1.4933e-08     \t|\n",
      "|  [Callback]LearningRateMonitor.on_fit_start                                                                                                                           \t|  7.6e-07        \t|  1              \t|  7.6e-07        \t|  1.3511e-08     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_end                                                                                                                           \t|  7.6e-07        \t|  1              \t|  7.6e-07        \t|  1.3511e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_end      \t|  7.6e-07        \t|  1              \t|  7.6e-07        \t|  1.3511e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_start    \t|  7.4e-07        \t|  1              \t|  7.4e-07        \t|  1.3156e-08     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                               \t|  7.3e-07        \t|  1              \t|  7.3e-07        \t|  1.2978e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_end      \t|  7.3e-07        \t|  1              \t|  7.3e-07        \t|  1.2978e-08     \t|\n",
      "|  [Callback]LearningRateMonitor.on_sanity_check_start                                                                                                                  \t|  7.2e-07        \t|  1              \t|  7.2e-07        \t|  1.28e-08       \t|\n",
      "|  [Callback]LearningRateMonitor.on_fit_end                                                                                                                             \t|  7e-07          \t|  1              \t|  7e-07          \t|  1.2445e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start             \t|  6.9e-07        \t|  1              \t|  6.9e-07        \t|  1.2267e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end             \t|  6.7e-07        \t|  1              \t|  6.7e-07        \t|  1.1911e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_start    \t|  6.3e-07        \t|  1              \t|  6.3e-07        \t|  1.12e-08       \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                        \t|  6.3e-07        \t|  1              \t|  6.3e-07        \t|  1.12e-08       \t|\n",
      "|  [LightningModule]GuruNet.on_fit_end                                                                                                                                  \t|  6e-07          \t|  1              \t|  6e-07          \t|  1.0667e-08     \t|\n",
      "|  [LightningModule]GuruNet.on_fit_start                                                                                                                                \t|  5.7e-07        \t|  1              \t|  5.7e-07        \t|  1.0133e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end             \t|  5.7e-07        \t|  1              \t|  5.7e-07        \t|  1.0133e-08     \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                                    \t|  5.3e-07        \t|  1              \t|  5.3e-07        \t|  9.4224e-09     \t|\n",
      "|  [LightningModule]GuruNet.on_train_end                                                                                                                                \t|  5.3e-07        \t|  1              \t|  5.3e-07        \t|  9.4223e-09     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                          \t|  5.2e-07        \t|  1              \t|  5.2e-07        \t|  9.2446e-09     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_pAUC', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end               \t|  5.2e-07        \t|  1              \t|  5.2e-07        \t|  9.2445e-09     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end               \t|  4.8e-07        \t|  1              \t|  4.8e-07        \t|  8.5334e-09     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                                 \t|  4.7e-07        \t|  1              \t|  4.7e-07        \t|  8.3557e-09     \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch': 0.34257519245147705,\n",
       "  'test_pAUC_epoch': 0.18955282866954803}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(\n",
    "    model=model,\n",
    "    ckpt_path=\"checkpoints/version_135/gurunet-epoch=48-val_pAUC=0.18755.ckpt\",\n",
    "    datamodule=data_module,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeoned",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
